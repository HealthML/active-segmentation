


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>functional &mdash; Active Segmentation 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
  

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="metric_tracking" href="metric_tracking.html" />
  <link rel="prev" title="datasets" href="datasets.html" /> 

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>


<div class="container-fluid header-holder docs-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="/" aria-label="Active Segmentation"></a>
      <div class="main-menu">
        <ul>
          <li>
            <a href="/">Home</a>
          </li>

          <li class="active docs-active">
            <a href="./">Docs</a>
          </li>

          <li>
            <a href="https://github.com/HealthML/active-segmentation">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="sphinx-template-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="sphinx-template-nav-shift" class="sphinx-template-left-menu" id="sphinx-template-left-menu">
    <div class="sphinx-template-side-scroll">
      <div class="sphinx-template-menu sphinx-template-menu-vertical" data-spy="affix" role="navigation"
        aria-label="main navigation">
        <div class="sphinx-template-left-menu-search">
          

          
          
          
          

          


<div role="search">
  <form id="rtd-search-form" class="sphinx-template-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="active_segmentation.html">active_learning_framework</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="active_learning.html">active_learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="inferencing.html">inferencing</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets.html">datasets</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric_tracking.html">metric_tracking</a></li>
<li class="toctree-l2"><a class="reference internal" href="models.html">models</a></li>
<li class="toctree-l2"><a class="reference internal" href="query_strategies.html">query_strategies</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="brats.html">The BraTS Dataset</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="sphinx-template-container">
    <div class="sphinx-template-page-level-bar" id="sphinx-template-page-level-bar">
      <div class="sphinx-template-breadcrumbs-wrapper">
        <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="sphinx-template-breadcrumbs">
      <li><a href="index.html" class="fa fa-large fa-home">Docs</a> &gt;</li>
          <li><a href="active_segmentation.html">active_learning_framework</a> &gt;</li>
      <li>functional</li>
      <li class="sphinx-template-breadcrumbs-aside">
            <a href="_sources/functional.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
      </li>
  </ul>
</div>
      </div>

      <div class="sphinx-template-shortcuts-wrapper" id="sphinx-template-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="sphinx-template-nav-shift" id="sphinx-template-content-wrap" class="sphinx-template-content-wrap">
      <div class="sphinx-template-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="sphinx-template-article" class="sphinx-template-article">
                
  <section id="functional">
<h1>functional<a class="headerlink" href="#functional" title="Permalink to this headline">¶</a></h1>
<section id="module-functional.losses">
<span id="losses"></span><h2>losses<a class="headerlink" href="#module-functional.losses" title="Permalink to this headline">¶</a></h2>
<p>Module containing segmentation losses</p>
<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.BCEDiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">BCEDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#BCEDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.BCEDiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implements a loss function that combines the Dice loss with the binary cross-entropy (negative log-likelihood) loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Reduction function that is to be used to aggregate the loss values of the images of
one batch, must be either “mean”, “sum” or “none”.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.BCEDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#BCEDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.BCEDiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask with each channel being either a sharp segmentation mask or
the output of a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask with the same number of channels as the prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Combined loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, and <cite>C = number of classes (excluding
the background)</cite>.</p></li>
<li><p>Target: <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in
<span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.BCEDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.BCEDiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.BCELoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">BCELoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#BCELoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.BCELoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Wrapper for the PyTorch implementation of BCE loss to ensure uniform reduction behaviour for all losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Reduction function that is to be used to aggregate the loss values of the images of
one batch, must be either “mean”, “sum” or “none”.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.BCELoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#BCELoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.BCELoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask with each channel being either a sharp segmentation mask or
the output of a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask with the same number of channels as the prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Binary cross-entropy loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, and <cite>C = number of classes (excluding
the background)</cite>.</p></li>
<li><p>Target: <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in
<span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.BCELoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.BCELoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.DiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">DiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#DiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.DiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implementation of Dice loss for segmentation tasks. The Dice loss originally was formulated in:</p>
<blockquote>
<div><p>Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi. V-net: Fully convolutional neural networks for
volumetric medical image segmentation, 2016.</p>
</div></blockquote>
<p>In this implementation an adapted version of the Dice loss is used that includes Laplacian smoothing.
For a discussion on different dice loss implementations, see <a class="reference external" href="https://github.com/pytorch/pytorch/issues/1249">https://github.com/pytorch/pytorch/issues/1249</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Reduction function that is to be used to aggregate the loss values of the images of
one batch, must be either “mean”, “sum” or “none”.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.DiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#DiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.DiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask with each channel being either a sharp segmentation mask or
the output of a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask with the same number of channels as the prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dice loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, and <cite>C = number of classes (excluding</cite>
<cite>the background)</cite>.</p></li>
<li><p>Target: <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in
<span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.DiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.DiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveDiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">FalsePositiveDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveDiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implements a loss function that combines the Dice loss with the false positive loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Reduction function that is to be used to aggregate the loss values of the images of
one batch, must be either “mean”, “sum” or “none”.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveDiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask with each channel being either a sharp segmentation mask or
the output of a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask with the same number of channels as the prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Combined loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, and <cite>C = number of classes (excluding
the background)</cite>.</p></li>
<li><p>Target: <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in
<span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.FalsePositiveDiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">FalsePositiveLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implementation of false positive loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Reduction function that is to be used to aggregate the loss values of the images of
one batch, must be either “mean”, “sum” or “none”.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask with each channel being either a sharp segmentation mask or
the output of a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask with the same number of channels as the prediction.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>False positive loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, and <cite>C = number of classes (excluding
the background)</cite>.</p></li>
<li><p>Target: <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in
<span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.FalsePositiveLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.SegmentationLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">SegmentationLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#SegmentationLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.SegmentationLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Base class for implementation of segmentation losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Reduction function that is to be used to aggregate the loss values of the images of
one batch, must be either “mean”, “sum” or “none”.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.SegmentationLoss.flatten_tensor">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">flatten_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#SegmentationLoss.flatten_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.SegmentationLoss.flatten_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Flattens a tensor except for its first two dimensions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor</strong> (<em>Tensor</em>) – The tensor to be flattened.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Flattened view of the input tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Tensor: <span class="math">\((N, C, X, Y, ...)\)</span></p></li>
<li><p>Output: <span class="math">\((N, C, X*Y*...)\)</span></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.SegmentationLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.SegmentationLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-functional.metrics">
<span id="metrics"></span><h2>metrics<a class="headerlink" href="#module-functional.metrics" title="Permalink to this headline">¶</a></h2>
<p>Module containing model evaluation metrics.</p>
<p>The metric implementations are based on the TorchMetrics framework. For instructions on how to implement custom metrics
with this framework, see <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/pages/implement.html">https://torchmetrics.readthedocs.io/en/latest/pages/implement.html</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.DiceScore">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">DiceScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#DiceScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.DiceScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.metric.Metric</span></code></p>
<p>Computes the Dice similarity coefficient (DSC). Can be used for 3D images whose slices are scattered over multiple
batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.DiceScore.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#DiceScore.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.DiceScore.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the DSC  over all slices that were registered using the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dice similarity coefficient.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.DiceScore.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#DiceScore.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.DiceScore.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">HausdorffDistance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">slices_per_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.metric.Metric</span></code></p>
<p>Computes the Hausdorff distance. Can be used for 3D images whose slices are scattered over multiple batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>slices_per_image</strong> (<em>int</em>) – Number of slices per 3d image.</p></li>
<li><p><strong>percentile</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentile for which the Hausdorff distance is to be calculated, must be in
<span class="math">\(\[0, 1\]\)</span>.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the Hausdorff distance should be normalized by dividing it by the diagonal
distance.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance.compute" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Computes the Hausdorf distance over all slices that were registered using the <cite>update</cite> method as the maximum per</dt><dd><p>slice-distance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Hausdorff distance.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.Sensitivity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">Sensitivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Sensitivity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Sensitivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.metric.Metric</span></code></p>
<p>Computes the sensitivity. Can be used for 3D images whose slices are scattered over multiple batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Sensitivity.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Sensitivity.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Sensitivity.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sensitivity  over all slices that were registered using the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Sensitivity.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Sensitivity.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Sensitivity.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Sensitivity.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.Specificity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">Specificity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Specificity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Specificity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.metric.Metric</span></code></p>
<p>Computes the specificity. Can be used for 3D images whose slices are scattered over multiple batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>smoothing</strong> (<em>int</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Specificity.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Specificity.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Specificity.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sensitivity  over all slices that were registered using the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Sensitivity.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Specificity.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Specificity.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Specificity.update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.dice_score">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">dice_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#dice_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.dice_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Dice similarity coefficient (DSC) between a predicted segmentation mask and the target mask:</p>
<blockquote>
<div><p><span class="math">\(DSC = \frac{2 \cdot TP}{2 \cdot TP + FP + FN}\)</span></p>
</div></blockquote>
<p>Using the <cite>smoothing</cite> parameter, Laplacian smoothing can be applied:</p>
<blockquote>
<div><p><span class="math">\(DSC = \frac{2 \cdot TP + \lambda}{2 \cdot TP + FP + FN + \lambda}\)</span></p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this method, the <cite>prediction</cite> tensor is considered as a segmentation mask of a single 2D or 3D image for a
given class and thus it aggregates over <span class="math">\(TP\)</span>, <span class="math">\(FP\)</span>, and <span class="math">\(FN\)</span> over all channels and dimensions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The predicted segmentation mask, where each value is in <span class="math">\([0, 1]\)</span>.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>smoothing</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dice similarity coefficient.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: Can have arbitrary dimensions. Typically <span class="math">\((S, height, width)\)</span>, where <cite>S = number of slices</cite>,
or <cite>(height, width)</cite> for single image segmentation tasks.</p></li>
<li><p>Target: Must have the same dimensions as the prediction.</p></li>
<li><p>Output: Scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.hausdorff_distance">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">hausdorff_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_image_locations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#hausdorff_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.hausdorff_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Hausdorff distance between a predicted segmentation mask and the target mask.
.. note:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>In this method, the `prediction` tensor is considered as a segmentation mask of a single 2D or 3D image for a
given class and thus the distances are calculated over all channels and dimensions.
As this method is implemented using the scipy package, the returned value is not differentiable in PyTorch and
can therefore not be used in loss functions.
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The predicted segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the Hausdorff distance should be normalized by dividing it by the diagonal
distance.</p></li>
<li><p><strong>percentile</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentile for which the Hausdorff distance is to be calculated, must be in
<span class="math">\(\[0, 1\]\)</span>.</p></li>
<li><p><strong>all_image_locations</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – A pre-computed tensor containing one point for each pixel in the
prediction representing the pixel’s location in 2d or 3d Euclidean space. Passing a pre-computed tensor to
this parameter can be used to speed up computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Hausdorff distance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: Can have arbitrary dimensions. Typically <span class="math">\((S, height, width)\)</span>, where <cite>S = number of slices</cite>,
or <cite>(height, width)</cite> for single image segmentation tasks.</p></li>
<li><p>Target: Must have the same dimensions as the prediction.</p></li>
<li><dl class="simple">
<dt>All_image_locations: Must contain one element per-pixel in the prediction. Each element represents an</dt><dd><p>n-dimensional point. Typically <span class="math">\((S \cdot height \cdot width, 3)\)</span>, where <cite>S = number of slices</cite>, or
<span class="math">\((height \cdot width, 2)\)</span></p>
</dd>
</dl>
</li>
<li><p>Output: Scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.sensitivity">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">sensitivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#sensitivity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.sensitivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sensitivity from a predicted segmentation mask and the target mask:</p>
<blockquote>
<div><p><span class="math">\(Sensitivity = \frac{TP}{TP + FN}\)</span></p>
</div></blockquote>
<p>Using the <cite>smoothing</cite> parameter, Laplacian smoothing can be applied:</p>
<blockquote>
<div><p><span class="math">\(Sensitivity = \frac{TP + \lambda}{TP + FN + \lambda}\)</span></p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this method, the <cite>prediction</cite> tensor is considered as a segmentation mask of a single 2D or 3D image for a
given class and thus it aggregates over <span class="math">\(TP\)</span>, and <span class="math">\(FN\)</span> over all channels and dimensions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The predicted segmentation mask, where each value is in <span class="math">\([0, 1]\)</span>.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>smoothing</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sensitivity.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: Can have arbitrary dimensions. Typically <span class="math">\((S, height, width)\)</span>, where <cite>S = number of slices</cite>,
or <cite>(height, width)</cite> for single image segmentation tasks.</p></li>
<li><p>Target: Must have the same dimensions as the prediction.</p></li>
<li><p>Output: Scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.specificity">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">specificity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">smoothing</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#specificity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.specificity" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the specificity from a predicted segmentation mask and the target mask:</p>
<blockquote>
<div><p><span class="math">\(Specificity = \frac{TN}{TN + FP}\)</span></p>
</div></blockquote>
<p>Using the <cite>smoothing</cite> parameter, Laplacian smoothing can be applied:</p>
<blockquote>
<div><p><span class="math">\(Specificity = \frac{TN + \lambda}{TN + FP + \lambda}\)</span></p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this method, the <cite>prediction</cite> tensor is considered as a segmentation mask of a single 2D or 3D image for a
given class and thus it aggregates over <span class="math">\(TP\)</span>, and <span class="math">\(FN\)</span> over all channels and dimensions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The predicted segmentation mask, where each value is in <span class="math">\([0, 1]\)</span>.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>smoothing</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing factor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Specificity.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Prediction: Can have arbitrary dimensions. Typically <span class="math">\((S, height, width)\)</span>, where <cite>S = number of slices</cite>,
or <cite>(height, width)</cite> for single image segmentation tasks.</p></li>
<li><p>Target: Must have the same dimensions as the prediction.</p></li>
<li><p>Output: Scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


              </article>
              
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="metric_tracking.html" class="btn btn-neutral float-right" title="metric_tracking" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="datasets.html" class="btn btn-neutral" title="datasets" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  
  
  <hr>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Masterprojekt &#34;Medical Image Segmentation&#34; (WS 2021/22, Prof. Lippert).

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using <a href="https://github.com/ain-soph/trojanzoo_sphinx_theme">trojanzoo_sphinx_theme</a> (modified from  <a href="https://github.com/ain-soph/pytorch_sphinx_theme">pytorch_sphinx_theme</a>).
      </div>
     

</footer>

          </div>
        </div>

        <div class="sphinx-template-content-right" id="sphinx-template-content-right">
          <div class="sphinx-template-right-menu" id="sphinx-template-right-menu">
            <div class="sphinx-template-side-scroll" id="sphinx-template-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">functional</a><ul>
<li><a class="reference internal" href="#module-functional.losses">losses</a></li>
<li><a class="reference internal" href="#module-functional.metrics">metrics</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  

  

  
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
  <script src="_static/jquery.js"></script>
  <script src="_static/underscore.js"></script>
  <script src="_static/doctools.js"></script>
  <script src="_static/clipboard.min.js"></script>
  <script src="_static/copybutton.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
  <script src="_static/katex_autorenderer.js"></script>
  

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  <script type="text/javascript">
    jQuery(function () {
      $('.header-logo').css('background-image', 'url()');
      $('.docs-header .header-logo').css('background-image', 'url()');
      $('.footer-logo').css('background-image', 'url()');
      });
  </script>
  <script script type="text/javascript">
    var collapsedSections = [];
  </script>
  

  <!-- Begin Footer -->

  <div class="container-fluid docs-resources" id="docs-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for Active Segmentation</p>
          <a class="with-right-arrow" href="index.html">View Docs</a>
        </div>
      </div>
    </div>
  </div>


  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="/" class="footer-logo"></a>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="/" aria-label="Active Segmentation"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>

          <li>
            <a href="/">Home</a>
          </li>

          <li class="active resources-mobile-menu-title">
            <a href="./">Docs</a>
          </li>
          <li>
            <a href="https://github.com/HealthML/active-segmentation">GitHub</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>


  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      trojanzooAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.sphinx-template-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>