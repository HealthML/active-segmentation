


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en">
<!--<![endif]-->

<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>functional package &mdash; Active Segmentation 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
  

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="index" title="Index" href="genindex.html" />
  <link rel="search" title="Search" href="search.html" />
  <link rel="next" title="metric_tracking package" href="metric_tracking.html" />
  <link rel="prev" title="datasets package" href="datasets.html" /> 

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"
    integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>


<div class="container-fluid header-holder docs-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="/" aria-label="Active Segmentation"></a>
      <div class="main-menu">
        <ul>
          <li>
            <a href="/">Home</a>
          </li>

          <li class="active docs-active">
            <a href="./">Docs</a>
          </li>

          <li>
            <a href="https://github.com/HealthML/active-segmentation">GitHub</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="sphinx-template-body">

   

  

  <div class="table-of-contents-link-wrapper">
    <span>Table of Contents</span>
    <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
  </div>

  <nav data-toggle="sphinx-template-nav-shift" class="sphinx-template-left-menu" id="sphinx-template-left-menu">
    <div class="sphinx-template-side-scroll">
      <div class="sphinx-template-menu sphinx-template-menu-vertical" data-spy="affix" role="navigation"
        aria-label="main navigation">
        <div class="sphinx-template-left-menu-search">
          

          
          
          
          

          


<div role="search">
  <form id="rtd-search-form" class="sphinx-template-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        
        
        
        
        
        <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="active_segmentation.html">Active Learning Framework</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="run_experiments.html">run_experiments module</a></li>
<li class="toctree-l2"><a class="reference internal" href="main.html">main module</a></li>
<li class="toctree-l2"><a class="reference internal" href="active_learning.html">active_learning module</a></li>
<li class="toctree-l2"><a class="reference internal" href="inferencing.html">inferencing module</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets.html">datasets package</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">functional package</a></li>
<li class="toctree-l2"><a class="reference internal" href="metric_tracking.html">metric_tracking package</a></li>
<li class="toctree-l2"><a class="reference internal" href="models.html">models package</a></li>
<li class="toctree-l2"><a class="reference internal" href="query_strategies.html">query_strategies package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="brats.html">The BraTS Dataset</a></li>
</ul>

        
        
      </div>
    </div>
  </nav>

  <div class="sphinx-template-container">
    <div class="sphinx-template-page-level-bar" id="sphinx-template-page-level-bar">
      <div class="sphinx-template-breadcrumbs-wrapper">
        <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="sphinx-template-breadcrumbs">
      <li><a href="index.html" class="fa fa-large fa-home">Docs</a> &gt;</li>
          <li><a href="active_segmentation.html">Active Learning Framework</a> &gt;</li>
      <li>functional package</li>
      <li class="sphinx-template-breadcrumbs-aside">
            <a href="_sources/functional.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
      </li>
  </ul>
</div>
      </div>

      <div class="sphinx-template-shortcuts-wrapper" id="sphinx-template-shortcuts-wrapper">
        Shortcuts
      </div>
    </div>

    <section data-toggle="sphinx-template-nav-shift" id="sphinx-template-content-wrap" class="sphinx-template-content-wrap">
      <div class="sphinx-template-content-left">
        
          <div class="rst-content">
            
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
              <article itemprop="articleBody" id="sphinx-template-article" class="sphinx-template-article">
                
  <section id="functional-package">
<h1>functional package<a class="headerlink" href="#functional-package" title="Permalink to this headline">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-functional.interpretation">
<span id="functional-interpretation-module"></span><h2>functional.interpretation module<a class="headerlink" href="#module-functional.interpretation" title="Permalink to this headline">¶</a></h2>
<p>Module to generate heat maps for trained model</p>
<dl class="py class">
<dt class="sig sig-object py" id="functional.interpretation.HeatMaps">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.interpretation.</span></span><span class="sig-name descname"><span class="pre">HeatMaps</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/interpretation.html#HeatMaps"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.interpretation.HeatMaps" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Generates heat maps for a trained model with respect to given layers.
SegGradCam (Gradient Based Activation Methods) are used to calculate relevance values of individual pixels.
Details can be found <a class="reference external" href="https://arxiv.org/abs/2002.11434">here</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>model</strong> (<a class="reference internal" href="models.html#models.pytorch_model.PytorchModel" title="models.pytorch_model.PytorchModel"><em>PytorchModel</em></a>) – A trained segmentation model.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.interpretation.HeatMaps.generate_grayscale_cam">
<span class="sig-name descname"><span class="pre">generate_grayscale_cam</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_category</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_layers</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/interpretation.html#HeatMaps.generate_grayscale_cam"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.interpretation.HeatMaps.generate_grayscale_cam" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the grayscale representation of the relevance of individual pixel values using GradCam.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<em>torch.Tensor</em>) – The tensor to calculate the desired values for.</p></li>
<li><p><strong>target_category</strong> (<em>int</em>) – The category or class of the predicted mask.</p></li>
<li><p><strong>target_layers</strong> (<em>List</em><em>[</em><em>torch.nn.Module</em><em>]</em>) – A list of layers of the given model architecture.
Used for calculating the gradient of the GradCam method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An array with the grayscale pixel importance values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.interpretation.HeatMaps.generate_grayscale_logits">
<span class="sig-name descname"><span class="pre">generate_grayscale_logits</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_category</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/interpretation.html#HeatMaps.generate_grayscale_logits"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.interpretation.HeatMaps.generate_grayscale_logits" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the grayscale representation of the relevance of individual pixel values using the model prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<em>torch.Tensor</em>) – The tensor to calculate the desired values for.</p></li>
<li><p><strong>target_category</strong> (<em>int</em>) – The category or class of the predicted mask.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>An array with the grayscale pixel importance values.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.interpretation.HeatMaps.show_grayscale_heatmap_on_image">
<em class="property"><span class="pre">static</span> </em><span class="sig-name descname"><span class="pre">show_grayscale_heatmap_on_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grayscale_heatmap</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/interpretation.html#HeatMaps.show_grayscale_heatmap_on_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.interpretation.HeatMaps.show_grayscale_heatmap_on_image" title="Permalink to this definition">¶</a></dt>
<dd><p>Maps the calculated grayscale relevance values to a given image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>np.ndarray</em>) – The image to map the pixel relevance values against.</p></li>
<li><p><strong>grayscale_heatmap</strong> (<em>np.ndarray</em>) – The calculated relevance values in grayscale format.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The input image in RGB format with mapped heatmap.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.interpretation.SemanticSegmentationTarget">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.interpretation.</span></span><span class="sig-name descname"><span class="pre">SemanticSegmentationTarget</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">category</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/interpretation.html#SemanticSegmentationTarget"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.interpretation.SemanticSegmentationTarget" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Wraps the target for generating heat maps.
All pixels belonging to the given prediction of the category will be summed up.
More details can be found <a class="reference external" href="https://arxiv.org/abs/2002.11434">here</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>category</strong> (<em>int</em>) – The category or class of the predicted mask.</p></li>
<li><p><strong>mask</strong> (<em>np.ndarray</em>) – The predicted mask as numpy array.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-functional.losses">
<span id="functional-losses-module"></span><h2>functional.losses module<a class="headerlink" href="#module-functional.losses" title="Permalink to this headline">¶</a></h2>
<p>Module containing segmentation losses</p>
<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.AbstractDiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">AbstractDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#AbstractDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.AbstractDiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Base class for implementation of Dice loss and Generalized Dice loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.AbstractDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#AbstractDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.AbstractDiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot
encoded.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dice loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding or <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.AbstractDiceLoss.get_dice_loss_module">
<em class="property"><span class="pre">abstract</span> </em><span class="sig-name descname"><span class="pre">get_dice_loss_module</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#AbstractDiceLoss.get_dice_loss_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.AbstractDiceLoss.get_dice_loss_module" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dice loss module.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.AbstractDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.AbstractDiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.CrossEntropyDiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">CrossEntropyDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#CrossEntropyDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.CrossEntropyDiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implements a loss function that combines the Dice loss with the binary cross-entropy (negative log-likelihood) loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multi_label</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is multilabel or not (default = <cite>False</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
Dice loss calculation, but not from the Cross-entropy loss calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.CrossEntropyDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#CrossEntropyDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.CrossEntropyDiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot
encoded.</p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Manual weight given to the loss of each image / slice. Defaults to <cite>None</cite>, which
means that all images are weighted equally.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Combined loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Weight: <span class="math">\((N)\)</span> where <cite>N = batch size</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.CrossEntropyDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.CrossEntropyDiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.CrossEntropyLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">CrossEntropyLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#CrossEntropyLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.CrossEntropyLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Wrapper for the PyTorch implementation of BCE loss / NLLLoss to ensure uniform reduction behaviour for all losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multi_label</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is multilabel or not (default = <cite>False</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.CrossEntropyLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#CrossEntropyLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.CrossEntropyLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot</p></li>
<li><p><strong>encoded.</strong> – </p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Manual weight given to the loss of each image / slice. Defaults to <cite>None</cite>, which
means that all images are weighted equally.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Cross-entropy loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Weight: <span class="math">\((N)\)</span> where <cite>N = batch size</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.CrossEntropyLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.CrossEntropyLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.DiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">DiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#DiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.DiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.AbstractDiceLoss" title="functional.losses.AbstractDiceLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.AbstractDiceLoss</span></code></a></p>
<p>Implementation of the Dice loss for segmentation tasks. The Dice loss for binary segmentation tasks originally was
formulated in:</p>
<blockquote>
<div><p><a class="reference external" href="https://arxiv.org/pdf/1606.04797.pdf">Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi. V-net: Fully convolutional neural networks for
volumetric medical image segmentation, 2016</a>.</p>
</div></blockquote>
<p>In this implementation an adapted version of the Dice loss is used that a includes an epsilon term :math:<a href="#id2"><span class="problematic" id="id3">`</span></a>epsilon`to
avoid divisions by zero and does not square the terms in the denominator. Additionally, the loss formulation is
generalized to multi-class classification tasks by averaging dice losses over the class and batch dimension:</p>
<blockquote>
<div><div class="math">
\[DL = 1 - \frac{1}{N \cdot L} \cdot \sum_{n=1}^N \sum_{l=1}^L 2 \cdot \frac{\sum_{i} r_{nli} p_{nli} +
\epsilon}{\sum_{n=1}^N \sum_{l=1}^L \sum_{i} (r_{nli} + p_{nli}) + \epsilon}

\]</div>
<p>where <span class="math">\(N\)</span> is the batch size, <span class="math">\(L\)</span> is the number of classes, <span class="math">\(r_{nli}\)</span> are the ground-truth
labels for class <span class="math">\(l\)</span> in the <span class="math">\(i\)</span>-th voxel of the <span class="math">\(n\)</span>-th image. Analogously, <span class="math">\(p\)</span> is the
predicted probability for class <span class="math">\(l\)</span> in the <span class="math">\(i\)</span>-th voxel of the <span class="math">\(n\)</span>-th image.</p>
</div></blockquote>
<p>This implementation is a wrapper of the Dice loss implementation from the <a class="reference external" href="https://docs.monai.io/en/stable/losses.html#diceloss">MONAI package</a> that adapts the reduction behaviour. It supports both
single-label and multi-label segmentation tasks. For a discussion on different dice loss implementations, see
<a class="reference external" href="https://github.com/pytorch/pytorch/issues/1249">https://github.com/pytorch/pytorch/issues/1249</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.DiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#DiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.DiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot
encoded.</p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Manual weight given to the loss of each image / slice. Defaults to <cite>None</cite>, which
means that all images are weighted equally.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dice loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Weight: <span class="math">\((N)\)</span> where <cite>N = batch size</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.DiceLoss.get_dice_loss_module">
<span class="sig-name descname"><span class="pre">get_dice_loss_module</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#DiceLoss.get_dice_loss_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.DiceLoss.get_dice_loss_module" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dice loss module.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.DiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.DiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveDiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">FalsePositiveDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveDiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implements a loss function that combines the Dice loss with the false positive loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveDiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot
encoded.</p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Manual weight given to the loss of each image / slice. Defaults to <cite>None</cite>, which
means that all images are weighted equally.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Combined loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Weight: <span class="math">\((N)\)</span> where <cite>N = batch size</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.FalsePositiveDiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">FalsePositiveLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.SegmentationLoss" title="functional.losses.SegmentationLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.SegmentationLoss</span></code></a></p>
<p>Implementation of false positive loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FalsePositiveLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FalsePositiveLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot</p></li>
<li><p><strong>encoded.</strong> – </p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Manual weight given to the loss of each image / slice. Defaults to <cite>None</cite>, which
means that all images are weighted equally.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>False positive loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Weight: <span class="math">\((N)\)</span> where <cite>N = batch size</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.FalsePositiveLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.FalsePositiveLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.FocalLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">FocalLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">multi_label</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">gamma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#FocalLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.FocalLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.CrossEntropyLoss" title="functional.losses.CrossEntropyLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.CrossEntropyLoss</span></code></a></p>
<p>Wrapper for the <cite>CrossEntropyLoss</cite> to perform some additional computations to turn it into focal loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>multi_label</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is multilabel or not (default = <cite>False</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
<li><p><strong>gamma</strong> (<em>float</em><em>, </em><em>optional</em>) – Specifies how far the loss of well-classified examples is down-weighed (default = <cite>5</cite>)</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.FocalLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.FocalLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.GeneralizedDiceLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">GeneralizedDiceLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight_type</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'square'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#GeneralizedDiceLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.GeneralizedDiceLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.losses.AbstractDiceLoss" title="functional.losses.AbstractDiceLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.losses.AbstractDiceLoss</span></code></a></p>
<p>Implementation of Generalized Dice loss for segmentation tasks. The Generalized Dice loss was formulated in:</p>
<blockquote>
<div><p><a class="reference external" href="https://arxiv.org/pdf/1707.03237.pdf">Carole H. Sudre, Wenqi Li, Tom Vercauteren, Sebastien Ourselin, and M. Jorge Cardoso: Generalised Dice overlap
as a deep learning loss function for highly unbalanced segmentations, 2017.</a></p>
</div></blockquote>
<p>It is formulated as:</p>
<blockquote>
<div><div class="math">
\[GDL = \frac{1}{N} \cdot \sum_{n=1}^N (1 - 2 \frac{\sum_{l=1}^L w_l \cdot \sum_{i} r_{nli} p_{nli} +
\epsilon}{\sum_{l=1}^L w_l \cdot \sum_{i} (r_{nli} + p_{nli}) + \epsilon})

\]</div>
<p>where <span class="math">\(N\)</span> is the batch size, <span class="math">\(L\)</span> is the number of classes, <span class="math">\(w_l\)</span> is a class weight,
<span class="math">\(r_{nli}\)</span> are the ground-truth labels for class <span class="math">\(l\)</span> in the <span class="math">\(i\)</span>-th voxel of the
<span class="math">\(n\)</span>-th image. Analogously, <span class="math">\(p\)</span> is the predicted probability for class <span class="math">\(l\)</span> in the
<span class="math">\(i\)</span>-th voxel of the <span class="math">\(n\)</span>-th image.</p>
</div></blockquote>
<p>This implementation is a wrapper of the Generalized Dice loss implementation from the <a class="reference external" href="https://docs.monai.io/en/stable/losses.html#generalizeddiceloss">MONAI package</a> that adapts the reduction behaviour. It supports
both single-label and multi-label segmentation tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>weight_type</strong> (<em>string</em><em>, </em><em>optional</em>) – Type of function to transform ground truth volume to a weight factor:
<cite>“square”</cite> | <cite>“simple”</cite> | <cite>“uniform”</cite>. Defaults to <cite>“square”</cite>.</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.GeneralizedDiceLoss.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#GeneralizedDiceLoss.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.GeneralizedDiceLoss.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – Predicted segmentation mask which is either the output of a softmax or a sigmoid layer.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – Target segmentation mask which is either label encoded, one-hot encoded or multi-hot
encoded.</p></li>
<li><p><strong>weight</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – Manual weight given to the loss of each image / slice. Defaults to <cite>None</cite>, which
means that all images are weighted equally.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Generalized dice loss.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((N, C, X, Y, ...)\)</span>, where <cite>N = batch size</cite>, <cite>C = number of classes</cite> and each value is</div>
<div class="line">in <span class="math">\([0, 1]\)</span></div>
</div>
</li>
<li><div class="line-block">
<div class="line">Target: <span class="math">\((N, X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((N, C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding.</div>
</div>
</li>
<li><p>Weight: <span class="math">\((N)\)</span> where <cite>N = batch size</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((N, C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.losses.GeneralizedDiceLoss.get_dice_loss_module">
<span class="sig-name descname"><span class="pre">get_dice_loss_module</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#GeneralizedDiceLoss.get_dice_loss_module"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.GeneralizedDiceLoss.get_dice_loss_module" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dice loss module.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Module</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.GeneralizedDiceLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.GeneralizedDiceLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.losses.SegmentationLoss">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.losses.</span></span><span class="sig-name descname"><span class="pre">SegmentationLoss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1e-10</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/losses.html#SegmentationLoss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.losses.SegmentationLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Base class for implementation of segmentation losses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input
gradient. Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>str</em><em>, </em><em>optional</em>) – Specifies the reduction to aggregate the loss values over the images of a batch and
multiple classes: <cite>“none”</cite> | <cite>“mean”</cite> | <cite>“sum”</cite>. <cite>“none”</cite>: no reduction will be applied, <cite>“mean”</cite>: the mean
of the output is taken, <cite>“sum”</cite>: the output will be summed (default = <cite>“mean”</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = <cite>1e-10</cite>).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="functional.losses.SegmentationLoss.training">
<span class="sig-name descname"><span class="pre">training</span></span><a class="headerlink" href="#functional.losses.SegmentationLoss.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-functional.metrics">
<span id="functional-metrics-module"></span><h2>functional.metrics module<a class="headerlink" href="#module-functional.metrics" title="Permalink to this headline">¶</a></h2>
<p>Module containing model evaluation metrics.</p>
<p>The metric implementations are based on the TorchMetrics framework. For instructions on how to implement custom metrics
with this framework, see <a class="reference external" href="https://torchmetrics.readthedocs.io/en/latest/pages/implement.html">https://torchmetrics.readthedocs.io/en/latest/pages/implement.html</a>.</p>
<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.DiceScore">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">DiceScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#DiceScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.DiceScore" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.metrics.SegmentationMetric" title="functional.metrics.SegmentationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.metrics.SegmentationMetric</span></code></a></p>
<p>Computes the Dice similarity coefficient (DSC). Can be used for 3D images whose slices are scattered over multiple
batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = 0).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>A method to reduce metric scores of multiple classes.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.DiceScore.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#DiceScore.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.DiceScore.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the DSC  over all slices that were registered using the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Dice similarity coefficient.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.DiceScore.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#DiceScore.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.DiceScore.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates metric using the provided prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding (<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">HausdorffDistance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slices_per_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.metrics.SegmentationMetric" title="functional.metrics.SegmentationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.metrics.SegmentationMetric</span></code></a></p>
<p>Computes the Hausdorff distance. Can be used for 3D images whose slices are scattered over multiple batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>slices_per_image</strong> (<em>int</em>) – Number of slices per 3d image.</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the Hausdorff distance should be normalized by dividing it by the diagonal
distance.</p></li>
<li><p><strong>percentile</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentile for which the Hausdorff distance is to be calculated, must be in
<span class="math">\(\[0, 1\]\)</span>.</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>A method to reduce metric scores of multiple classes (default = <cite>“none”</cite>).</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Hausdorff distance over all slices that were registered using the <cite>update</cite> method as the maximum
per slice-distance.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Hausdorff distance.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance.reset">
<span class="sig-name descname"><span class="pre">reset</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance.reset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Resets the metric state.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.HausdorffDistance.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">slice_ids</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#HausdorffDistance.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.HausdorffDistance.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates metric using the provided prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
<li><p><strong>slice_ids</strong> (<em>Union</em><em>[</em><em>int</em><em>, </em><em>List</em><em>[</em><em>int</em><em>]</em><em>]</em>) – Indices of the image slices represented by <cite>prediction</cite> and <cite>target</cite>.
Must be provided if <cite>target</cite> is a single slice or a subset of slices taken from a 3d image.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding (<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.SegmentationMetric">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">SegmentationMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#SegmentationMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.SegmentationMetric" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchmetrics.metric.Metric</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Base class for segmentation metrics.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>ignore_value</strong> (<em>float</em><em>, </em><em>optional</em>) – Value that should be inserted at the positions where the target is equal to
<cite>ignore_index</cite>. Defaults to 0.</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>A method to reduce metric scores of multiple classes.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.Sensitivity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">Sensitivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Sensitivity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Sensitivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.metrics.SegmentationMetric" title="functional.metrics.SegmentationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.metrics.SegmentationMetric</span></code></a></p>
<p>Computes the sensitivity. Can be used for 3D images whose slices are scattered over multiple batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = 0).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>A method to reduce metric scores of multiple classes.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Sensitivity.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Sensitivity.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Sensitivity.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sensitivity  over all slices that were registered using the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Sensitivity.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Sensitivity.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Sensitivity.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Sensitivity.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates metric using the provided prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding (<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="functional.metrics.Specificity">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">Specificity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Specificity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Specificity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#functional.metrics.SegmentationMetric" title="functional.metrics.SegmentationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">functional.metrics.SegmentationMetric</span></code></a></p>
<p>Computes the specificity. Can be used for 3D images whose slices are scattered over multiple batches.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing term to avoid divisions by zero (default = 0).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – <p>A method to reduce metric scores of multiple classes (default = <cite>“none”</cite>).</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Specificity.compute">
<span class="sig-name descname"><span class="pre">compute</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Specificity.compute"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Specificity.compute" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sensitivity  over all slices that were registered using the <cite>update</cite> method.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Sensitivity.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="functional.metrics.Specificity.update">
<span class="sig-name descname"><span class="pre">update</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#Specificity.update"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.Specificity.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates metric using the provided prediction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label</div>
<div class="line">encoding and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or</div>
<div class="line">multi-hot encoding (<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.dice_score">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">dice_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#dice_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.dice_score" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Dice similarity coefficient (DSC) between a predicted segmentation mask and the target mask:</p>
<blockquote>
<div><p><span class="math">\(DSC = \frac{2 \cdot TP}{2 \cdot TP + FP + FN}\)</span></p>
</div></blockquote>
<p>Using the <cite>epsilon</cite> parameter, Laplacian smoothing can be applied:</p>
<blockquote>
<div><p><span class="math">\(DSC = \frac{2 \cdot TP + \lambda}{2 \cdot TP + FP + FN + \lambda}\)</span></p>
</div></blockquote>
<p>This metric supports both single-label and multi-label segmentation tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing factor (default = 0).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>string</em>) – A method to reduce metric scores of multiple classes.
- <code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)
- <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean
- <code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum
- <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Dice similarity coefficient.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label encoding</div>
<div class="line">and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or multi-hot encoding</div>
<div class="line">(<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.hausdorff_distance">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">hausdorff_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_image_locations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#hausdorff_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.hausdorff_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Hausdorff distance between a predicted segmentation mask and the target mask.</p>
<p>This metric supports both single-label and multi-label segmentation tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>all_image_locations</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – A pre-computed tensor containing one point for each pixel in the
prediction representing the pixel’s location in 2d or 3d Euclidean space. Passing a pre-computed tensor to
this parameter can be used to speed up computation.</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the Hausdorff distance should be normalized by dividing it by the diagonal
distance.</p></li>
<li><p><strong>percentile</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentile for which the Hausdorff distance is to be calculated, must be in
<span class="math">\(\[0, 1\]\)</span>.</p></li>
<li><p><strong>reduction</strong> (<em>string</em>) – A method to reduce metric scores of multiple classes.
- <code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)
- <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean
- <code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum
- <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Hausdorff distance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label encoding</div>
<div class="line">and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or multi-hot encoding</div>
<div class="line">(<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.sensitivity">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">sensitivity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#sensitivity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.sensitivity" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the sensitivity from a predicted segmentation mask and the target mask:</p>
<blockquote>
<div><p><span class="math">\(Sensitivity = \frac{TP}{TP + FN}\)</span></p>
</div></blockquote>
<p>Using the <cite>epsilon</cite> parameter, Laplacian smoothing can be applied:</p>
<blockquote>
<div><p><span class="math">\(Sensitivity = \frac{TP + \lambda}{TP + FN + \lambda}\)</span></p>
</div></blockquote>
<p>This metric supports both single-label and multi-label segmentation tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing factor (default = 0).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>string</em>) – A method to reduce metric scores of multiple classes.
- <code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)
- <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean
- <code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum
- <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Sensitivity.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label encoding</div>
<div class="line">and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or multi-hot encoding</div>
<div class="line">(<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.single_class_hausdorff_distance">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">single_class_hausdorff_distance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalize</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">percentile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.95</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">all_image_locations</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#single_class_hausdorff_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.single_class_hausdorff_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the Hausdorff distance between a predicted segmentation mask and the target mask.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In this method, the <cite>prediction</cite> tensor is considered as a segmentation mask of a single 2D or 3D image for a
given class and thus the distances are calculated over all channels and dimensions.
As this method is implemented using the scipy package, the returned value is not differentiable in PyTorch and
can therefore not be used in loss functions.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The predicted segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target segmentation mask, where each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p><strong>normalize</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether the Hausdorff distance should be normalized by dividing it by the diagonal
distance.</p></li>
<li><p><strong>percentile</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentile for which the Hausdorff distance is to be calculated, must be in
<span class="math">\(\[0, 1\]\)</span>.</p></li>
<li><p><strong>all_image_locations</strong> (<em>Tensor</em><em>, </em><em>optional</em>) – A pre-computed tensor containing one point for each pixel in the
prediction representing the pixel’s location in 2d or 3d Euclidean space. Passing a pre-computed tensor to
this parameter can be used to speed up computation.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Hausdorff distance.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: Can have arbitrary dimensions. Typically <span class="math">\((S, height, width)\)</span>, where</div>
<div class="line"><cite>S = number of slices</cite>, or <cite>(height, width)</cite> for single image segmentation tasks.</div>
</div>
</li>
<li><p>Target: Must have the same dimensions as the prediction.</p></li>
<li><div class="line-block">
<div class="line">All_image_locations: Must contain one element per-pixel in the prediction. Each element represents an</div>
<div class="line">n-dimensional point. Typically <span class="math">\((S \cdot height \cdot width, 3)\)</span>, where <cite>S = number of slices</cite>, or</div>
<div class="line"><span class="math">\((height \cdot width, 2)\)</span></div>
</div>
</li>
<li><p>Output: Scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.metrics.specificity">
<span class="sig-prename descclassname"><span class="pre">functional.metrics.</span></span><span class="sig-name descname"><span class="pre">specificity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'none'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/metrics.html#specificity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.metrics.specificity" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the specificity from a predicted segmentation mask and the target mask:</p>
<blockquote>
<div><p><span class="math">\(Specificity = \frac{TN}{TN + FP}\)</span></p>
</div></blockquote>
<p>Using the <cite>epsilon</cite> parameter, Laplacian smoothing can be applied:</p>
<blockquote>
<div><p><span class="math">\(Specificity = \frac{TN + \lambda}{TN + FP + \lambda}\)</span></p>
</div></blockquote>
<p>This metric supports both single-label and multi-label segmentation tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – Laplacian smoothing factor (default = 0).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
<li><p><strong>reduction</strong> (<em>string</em>) – A method to reduce metric scores of multiple classes.
- <code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied (default)
- <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean
- <code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum
- <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Specificity.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> where each value is in <span class="math">\(\{0, ..., C - 1\}\)</span> in case of label encoding</div>
<div class="line">and <span class="math">\((C, X, Y, ...)\)</span>, where each value is in <span class="math">\(\{0, 1\}\)</span> in case of one-hot or multi-hot encoding</div>
<div class="line">(<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape and type as prediction.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-functional.utils">
<span id="functional-utils-module"></span><h2>functional.utils module<a class="headerlink" href="#module-functional.utils" title="Permalink to this headline">¶</a></h2>
<p>Utilities for metric and loss computations.</p>
<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.flatten_tensors">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">flatten_tensors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">include_background</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#flatten_tensors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.flatten_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Reshapes and flattens prediction and target tensors except for the first dimension (class dimension).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor (one-hot encoded or multi-hot encoded).</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor (one-hot encoded or multi-hot encoded).</p></li>
<li><p><strong>include_background</strong> (<em>bool</em><em>, </em><em>optional</em>) – if <cite>False</cite>, class channel index 0 (background class) is excluded from the
calculation (default = <cite>True</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Flattened prediction and target tensors (one-hot or multi-hot encoded).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Tensor]</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Prediction: <span class="math">\((C, X, Y, ...)\)</span>, where <cite>C = number of classes</cite> and each value is in <span class="math">\(\{0, 1\}\)</span>.</p></li>
<li><p>Target: Must have same shape and type as prediction.</p></li>
<li><div class="line-block">
<div class="line">Output: <span class="math">\((C, X * Y * ...)\)</span> where each element is in <span class="math">\(\{0, 1\}\)</span> indicating the absence /</div>
<div class="line">presence of the respective class (one-hot or multi-hot encoding).</div>
</div>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.is_binary">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">is_binary</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor_to_check</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#is_binary"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.is_binary" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks whether the input contains only zeros and ones.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>tensor_to_check</strong> (<em>Tensor</em>) – tensor to check.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if contains only zeros and ones, False otherwise.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.mask_tensor">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">mask_tensor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mask_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#mask_tensor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.mask_tensor" title="Permalink to this definition">¶</a></dt>
<dd><p>Replaces the tensor’s values in the positions where the mask is equal to <cite>ignore_index</cite> with <cite>mask_value</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>Tensor</em>) – A tensor in which is to be masked.</p></li>
<li><p><strong>mask</strong> (<em>Tensor</em>) – A mask tensor containing the <code class="xref py py-attr docutils literal notranslate"><span class="pre">ignore_index</span></code> at the positions to be masked.</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Label index indicating the positions to be masked.</p></li>
<li><p><strong>mask_value</strong> (<em>float</em><em>, </em><em>optional</em>) – Value that should be inserted at the masked positions. Defaults to 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Masked tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Tensor: <span class="math">\((N, C, X, Y, ...)\)</span> or <span class="math">\((C, X, Y, ...)\)</span>.</p></li>
<li><div class="line-block">
<div class="line">Mask: <span class="math">\((N, 1, X, Y, ...)\)</span> / <span class="math">\((N, C, X, Y, ...)\)</span> or <span class="math">\((1, X, Y, ...)\)</span> /</div>
<div class="line"><span class="math">\((C, X, Y, ...)\)</span>.</div>
</div>
</li>
<li><p>Output: Same shape as input.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.one_hot_encode">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">one_hot_encode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#one_hot_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.one_hot_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Converts a label encoded tensor to a one-hot encoded tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<em>Tensor</em>) – Label encoded tensor that is to be converted to one-hot encoding.</p></li>
<li><p><strong>dim</strong> (<em>int</em>) – Dimensionality of the input. Either 2 or 3.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (excluding the class labeled with <code class="xref py py-attr docutils literal notranslate"><span class="pre">ignore_label</span></code>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Class value for which no one-hot encoded channel should be created in the output.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>One-hot encoded tensor.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Tensor: <span class="math">\((N, X, Y, ...)\)</span> or <span class="math">\((X, Y, ...)\)</span> where each element represents a class index of integer</div>
<div class="line">type and <cite>N = batch size</cite>.</div>
</div>
</li>
<li><div class="line-block">
<div class="line">Output: <span class="math">\((N, C, X, Y, ...)\)</span> or <span class="math">\((C, X, Y, ...)\)</span> where each element represent a binary class</div>
<div class="line">label and <span class="math">\(C\)</span> is the number of classes (excluding the ignored class labeled with</div>
<div class="line"><code class="xref py py-attr docutils literal notranslate"><span class="pre">ignore_label</span></code>).</div>
</div>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.preprocess_metric_inputs">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">preprocess_metric_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_value</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#preprocess_metric_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.preprocess_metric_inputs" title="Permalink to this definition">¶</a></dt>
<dd><p>This method implements preprocessing steps that are needed for most segmentation metrics:</p>
<ol class="arabic simple">
<li><p>Validation of input shape and type</p></li>
<li><p>Conversion from label encoding to one-hot encoding if necessary</p></li>
<li><p>Mapping of pixels/voxels labeled with the <code class="xref py py-attr docutils literal notranslate"><span class="pre">ignore_index</span></code> to true negatives or true positives</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor to be preprocessed.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor to be preprocessed.</p></li>
<li><p><strong>num_classes</strong> (<em>int</em>) – Number of classes (for single-label segmentation tasks including the background class).</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and needs to be converted to one-hot
encoding or not (default = <cite>True</cite>).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em><em>, </em><em>optional</em>) – Specifies a target value that is ignored and does not contribute to the metric.
Defaults to <cite>None</cite>.</p></li>
<li><p><strong>ignore_value</strong> (<em>float</em><em>, </em><em>optional</em>) – Value that should be inserted at the positions where the target is equal to
<cite>ignore_index</cite>. Defaults to 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The preprocessed prediction and target tensors.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Tensor, Tensor]</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.reduce_metric">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">reduce_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#reduce_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.reduce_metric" title="Permalink to this definition">¶</a></dt>
<dd><p>Aggregates the metric values of the different classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric</strong> (<em>Tensor</em>) – Metrics to be aggregated.</p></li>
<li><p><strong>reduction</strong> (<em>string</em>) – A method to reduce metric scores of multiple classes.
- <code class="docutils literal notranslate"><span class="pre">&quot;none&quot;</span></code>: no reduction will be applied
- <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code>: takes the mean
- <code class="docutils literal notranslate"><span class="pre">&quot;min&quot;</span></code>: takes the minimum
- <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>: takes the maximum</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Aggregated metric value.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tensor</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Metric: <span class="math">\((C)\)</span>, where <cite>C = number of classes</cite>.</p></li>
<li><p>Output: If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <cite>“none”</cite>, shape <span class="math">\((C)\)</span>. Otherwise, scalar.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.remove_padding">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">remove_padding</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ignore_index</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">is_label_encoded</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#remove_padding"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.remove_padding" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes padding from prediction and target tensor. For this purpose, the areas where the target tensor is
equal to <code class="xref py py-attr docutils literal notranslate"><span class="pre">ignore_index</span></code> are removed from both tensors. It is assumed that whole rows or columns are padded
always.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – A prediction tensor (label-encoded, one-hot encoded, or multi-hot encoded).</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – A target tensor (with same encoding as prediction tensor).</p></li>
<li><p><strong>ignore_index</strong> (<em>int</em>) – Specifies the target value that is used as label for padded areas.</p></li>
<li><p><strong>is_label_encoded</strong> (<em>bool</em>) – Whether the input data are label encoded or one-hot / multi-hot encoded.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Prediction and target tensors without padding areas.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Tensor, Tensor]</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><div class="line-block">
<div class="line">Prediction: <span class="math">\((X, Y, ...)\)</span> in case of label encoding and <span class="math">\((C, X, Y, ...)\)</span>, in case of one-hot</div>
<div class="line">or multi-hot encoding (<cite>C = number of classes</cite>).</div>
</div>
</li>
<li><p>Target: Same shape as prediction.</p></li>
<li><div class="line-block">
<div class="line">Output: <span class="math">\((X - P_x, Y - P_y, ...)\)</span> in case of label encoding and <span class="math">\((C, X - P_x, Y - P_y, ...)\)</span>,</div>
<div class="line">in case of one-hot or multi-hot encoding (<cite>C = number of classes</cite>, <cite>P_x = padding width on x-axis</cite>).</div>
</div>
</li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="functional.utils.validate_metric_inputs">
<span class="sig-prename descclassname"><span class="pre">functional.utils.</span></span><span class="sig-name descname"><span class="pre">validate_metric_inputs</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">prediction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convert_to_one_hot</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/functional/utils.html#validate_metric_inputs"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#functional.utils.validate_metric_inputs" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Validates the inputs for segmentation metric computations:</dt><dd><ul class="simple">
<li><p>Checks that prediction and target are both on the same device.</p></li>
<li><p>Checks that prediction and target have the correct shape and type.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prediction</strong> (<em>Tensor</em>) – The prediction tensor to be validated.</p></li>
<li><p><strong>target</strong> (<em>Tensor</em>) – The target tensor to be validated.</p></li>
<li><p><strong>convert_to_one_hot</strong> (<em>bool</em><em>, </em><em>optional</em>) – Determines if data is label encoded and is intended to be converted to
one-hot encoding or not (default = <cite>True</cite>).</p></li>
</ul>
</dd>
<dt class="field-even">Raises</dt>
<dd class="field-even"><p><strong>AssertionError</strong> – if input tensors violate any of the validation criteria.</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-functional">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-functional" title="Permalink to this headline">¶</a></h2>
</section>
</section>


              </article>
              
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="metric_tracking.html" class="btn btn-neutral float-right" title="metric_tracking package" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="datasets.html" class="btn btn-neutral" title="datasets package" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  
  
  <hr>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, Masterprojekt &#34;Medical Image Segmentation&#34; (WS 2021/22, Prof. Lippert).

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using <a href="https://github.com/ain-soph/trojanzoo_sphinx_theme">trojanzoo_sphinx_theme</a> (modified from  <a href="https://github.com/ain-soph/pytorch_sphinx_theme">pytorch_sphinx_theme</a>).
      </div>
     

</footer>

          </div>
        </div>

        <div class="sphinx-template-content-right" id="sphinx-template-content-right">
          <div class="sphinx-template-right-menu" id="sphinx-template-right-menu">
            <div class="sphinx-template-side-scroll" id="sphinx-template-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">functional package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-functional.interpretation">functional.interpretation module</a></li>
<li><a class="reference internal" href="#module-functional.losses">functional.losses module</a></li>
<li><a class="reference internal" href="#module-functional.metrics">functional.metrics module</a></li>
<li><a class="reference internal" href="#module-functional.utils">functional.utils module</a></li>
<li><a class="reference internal" href="#module-functional">Module contents</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
    </section>
  </div>

  

  

  
  <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
  <script src="_static/jquery.js"></script>
  <script src="_static/underscore.js"></script>
  <script src="_static/doctools.js"></script>
  <script src="_static/clipboard.min.js"></script>
  <script src="_static/copybutton.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/contrib/auto-render.min.js"></script>
  <script src="_static/katex_autorenderer.js"></script>
  

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  <script type="text/javascript">
    jQuery(function () {
      $('.header-logo').css('background-image', 'url()');
      $('.docs-header .header-logo').css('background-image', 'url()');
      $('.footer-logo').css('background-image', 'url()');
      });
  </script>
  <script script type="text/javascript">
    var collapsedSections = [];
  </script>
  

  <!-- Begin Footer -->

  <div class="container-fluid docs-resources" id="docs-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for Active Segmentation</p>
          <a class="with-right-arrow" href="index.html">View Docs</a>
        </div>
      </div>
    </div>
  </div>


  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="/" class="footer-logo"></a>
      </div>
    </div>
  </footer>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="/" aria-label="Active Segmentation"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>

          <li>
            <a href="/">Home</a>
          </li>

          <li class="active resources-mobile-menu-title">
            <a href="./">Docs</a>
          </li>
          <li>
            <a href="https://github.com/HealthML/active-segmentation">GitHub</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>


  <script type="text/javascript">
    $(document).ready(function () {
      mobileMenu.bind();
      mobileTOC.bind();
      trojanzooAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.sphinx-template-article a span.pre").each(function (e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>

</html>