{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from typing import Dict, Iterable, List, Literal, Optional, Tuple, Union\n",
    "\n",
    "import itk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import wandb\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(run_id: str, entity_name: str, project_name: str, table_name: str, iterations: Union[int, List[int]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads specified table artifacts of a given Weights and Biases run.\n",
    "\n",
    "    Args:\n",
    "        run_id (string): ID of the Weights and Biases run.\n",
    "        entity_name (string): Name of the Weights and Biases entity to which the run belongs.\n",
    "        project_name (string): Name of the Weights and Biases project to which the run belongs.\n",
    "        table_name (string): Name of the tabel artifact to be loaded.\n",
    "        iterations (Union[int, List[int]]): Active learning iterations for which the tables are to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Concatenated tables for the specified active learning iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(iterations, int):\n",
    "        iterations = [iterations]\n",
    "    tables = []\n",
    "    with wandb.init(entity=entity_name, project=project_name) as run:\n",
    "        for iteration in iterations:\n",
    "            table = run.use_artifact(f\"run-{run_id}-{table_name}:v{iteration-1}\").get(table_name)\n",
    "            table = pd.DataFrame(table.data, columns=table.columns)\n",
    "            tables.append(table)\n",
    "\n",
    "    return pd.concat(tables)\n",
    "\n",
    "def download_all_tables(run_id: str, entity_name: str, project_name: str, table_name: str):\n",
    "    \"\"\"\n",
    "    Loads all table artifacts of a given Weights and Biases run.\n",
    "\n",
    "    Args:\n",
    "        run_id (string): ID of the Weights and Biases run.\n",
    "        entity_name (string): Name of the Weights and Biases entity to which the run belongs.\n",
    "        project_name (string): Name of the Weights and Biases project to which the run belongs.\n",
    "        table_name (string): Name of the tabel artifact to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Concatenated tables for all active learning iterations.\n",
    "    \"\"\"\n",
    "\n",
    "    run = api.run(f\"/active-segmentation/{project_name}/runs/{run_id}\")\n",
    "    run_metrics = run.history()\n",
    "    max_iteration = int(run_metrics[\"trainer/iteration\"].max())\n",
    "\n",
    "    selected_items = load_table(run.id, entity_name, project_name, table_name, list(range(1, max_iteration+1)))\n",
    "\n",
    "    selected_items.to_csv(f\"{run.name}_{run.id}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image: np.ndarray, mask: Optional[np.ndarray] = None) -> None:\n",
    "    \"\"\"\n",
    "    Plots a single image.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Image to be plotted. Must have shape `(h, w)` where `image height`, and `w = image width`.\n",
    "        mask (numpy.ndarray, optional): Mask to be plotted onto the image. Must have same shape as `image`. Defaults to `None`.\n",
    "    \"\"\"\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "\n",
    "    if mask is not None:\n",
    "        cmap = cm.Accent.copy()\n",
    "        cmap.set_under('k', alpha=0)\n",
    "\n",
    "        plt.imshow(mask, cmap=cmap, alpha=0.7, clim=[0.9, 10])\n",
    "\n",
    "\n",
    "def plot_images(images: List[np.array], masks: Optional[List[np.array]] = None, max_images: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Plots several images.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Images to be plotted. Must have shape `(N, h, w)` where `N = number of images`,\n",
    "            ` h = image height`, and `w = image width`.\n",
    "        mask (numpy.ndarray, optional): Masks to be plotted onto the images. Must have same shape as `image`. Defaults to `None`.\n",
    "        max_images (int): Maximum number of images to be plotted.\n",
    "    \"\"\"\n",
    "    \n",
    "    images = images[:max_images]\n",
    "\n",
    "    plt.figure(figsize=(32 * len(images), 32))\n",
    "    for idx, image in enumerate(images):\n",
    "        plt.subplot(1, len(images), idx+1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "\n",
    "        if masks is not None:\n",
    "            cmap = cm.Accent.copy()\n",
    "            cmap.set_under('k', alpha=0)\n",
    "\n",
    "            plt.imshow(masks[idx], cmap=cmap, alpha=0.7, clim=[0.9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signed_distance_interpolation(\n",
    "    top: np.array,\n",
    "    bottom: np.array,\n",
    "    block_thickness: int,\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    Interpolates between top and bottom slices if possible. Uses a signed distance function to interpolate.\n",
    "\n",
    "    Args:\n",
    "        top (np.array): The top slice of the block.\n",
    "        bottom (np.array): The bottom slice of the block.\n",
    "        block_thickness (int): The thickness of the block.\n",
    "    Returns:\n",
    "        np.array: The interpolated slices between top and bottom.\n",
    "    \"\"\"\n",
    "\n",
    "    def signed_dist(mask):\n",
    "        inverse_mask = np.ones(mask.shape) - mask\n",
    "        return distance_transform_edt(mask) - distance_transform_edt(inverse_mask) + 0.5\n",
    "\n",
    "    def interpolation(start, end, dist):\n",
    "        dist_start = signed_dist(start)\n",
    "        dist_end = signed_dist(end)\n",
    "        interp = (dist_start * (1 - dist)) + (dist_end * dist)\n",
    "        interp = interp >= 0\n",
    "        return interp\n",
    "\n",
    "    step = 1 / (block_thickness - 1)\n",
    "    interpolation_steps = [i * step for i in range(1, block_thickness - 1)]\n",
    "\n",
    "    return np.array([interpolation(top, bottom, step) for step in interpolation_steps])\n",
    "\n",
    "\n",
    "def morphological_contour_interpolation(\n",
    "    top: np.array,\n",
    "    bottom: np.array,\n",
    "    block_thickness: int,\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    Interpolates between top and bottom slices using the `morphological_contour_interpolator\n",
    "    <https://www.researchgate.net/publication/307942551_ND_morphological_contour_interpolation>`_ from ITK.\n",
    "\n",
    "    Args:\n",
    "        top (np.array): The top slice of the block.\n",
    "        bottom (np.array): The bottom slice of the block.\n",
    "        block_thickness (int): The thickness of the block.\n",
    "    Returns:\n",
    "        np.array: The interpolated slices between top and bottom.\n",
    "    \"\"\"\n",
    "\n",
    "    block = np.zeros((block_thickness, *top.shape))\n",
    "    block[0, :, :] = bottom\n",
    "    block[-1, :, :] = top\n",
    "    image_type = itk.Image[itk.UC, 3]\n",
    "    itk_img = itk.image_from_array(block.astype(np.uint8), ttype=(image_type,))\n",
    "    image = itk.morphological_contour_interpolator(itk_img)\n",
    "    interpolated_block = itk.GetArrayFromImage(image)\n",
    "    interpolated_slices = interpolated_block[1:-1, :, :]\n",
    "\n",
    "    return interpolated_slices.astype(bool)\n",
    "\n",
    "    \n",
    "def interpolate_slices(\n",
    "    top: np.array,\n",
    "    bottom: np.array,\n",
    "    class_ids: Iterable[int],\n",
    "    block_thickness: int,\n",
    "    interpolation_type: Literal[\"signed-distance\", \"morph-contour\"],\n",
    ") -> Optional[np.array]:\n",
    "    \"\"\"\n",
    "    Interpolates between top and bottom slices if possible. Uses a signed distance function to interpolate.\n",
    "\n",
    "    Args:\n",
    "        top (np.array): The top slice of the block.\n",
    "        bottom (np.array): The bottom slice of the block.\n",
    "        class_ids (Iterable[int]): The class ids.\n",
    "        block_thickness (int): The thickness of the block.\n",
    "        interpolation_type (Literal): The type of interpolation to use. One of [\"signed-distance\", \"morph-contour\"]\n",
    "    Returns:\n",
    "        Optional[np.array]: The interpolated slices between top and bottom.\n",
    "    \"\"\"\n",
    "\n",
    "    interpolation_thickness = block_thickness - 2\n",
    "\n",
    "    single_class_interpolations = {}\n",
    "    for class_id in class_ids:\n",
    "        class_top = top == class_id\n",
    "        class_bottom = bottom == class_id\n",
    "\n",
    "        if not np.any(class_top) and not np.any(class_bottom):\n",
    "            single_class_interpolations[class_id] = np.zeros(\n",
    "                (interpolation_thickness, *top.shape), dtype=bool\n",
    "            )\n",
    "        elif not np.any(np.logical_and(class_top, class_bottom)):\n",
    "            return None\n",
    "        else:\n",
    "            if interpolation_type == \"signed-distance\":\n",
    "                interpolation_fn = signed_distance_interpolation\n",
    "\n",
    "            elif interpolation_type == \"morph-contour\":\n",
    "                interpolation_fn = morphological_contour_interpolation\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Invalid interpolation type {interpolation_type}.\"\n",
    "                )\n",
    "\n",
    "            slices = interpolation_fn(class_top, class_bottom, block_thickness)\n",
    "            single_class_interpolations[class_id] = slices\n",
    "\n",
    "    result = np.zeros((interpolation_thickness, *top.shape))\n",
    "\n",
    "    for class_id, interpolation in single_class_interpolations.items():\n",
    "        result[interpolation] = class_id\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_blocks(run_id: str,\n",
    "                        entity_name: str,\n",
    "                        project_name: str,\n",
    "                        table_name: str,\n",
    "                        iteration: int,\n",
    "                        class_ids: Dict[int, str], \n",
    "                        interpolation_type: Literal[\"signed-distance\", \"morph-contour\"] = \"signed-distance\") -> List[Tuple[List[str], List[bool], np.ndarray, np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Assembles the blocks selected in the given active learning run and iteration.\n",
    "\n",
    "    Args:\n",
    "        run_id (string): ID of the Weights and Biases run.\n",
    "        entity_name (string): Name of the Weights and Biases entity to whicht the run belongs.\n",
    "        project_name (string): Name of the Weights and Biases project to whicht the run belongs.\n",
    "        table_name (string): Name of the table artifact to which the selected slices are logged.\n",
    "        iteration (int): Active learning iteration for which the selected blocks are to be assembled.\n",
    "        class_ids (Dict[int, str]): Mapping of class IDs to class names.\n",
    "        interpolation_type (Literal): The type of interpolation to use. One of [\"signed-distance\", \"morph-contour\"]\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[List[str], List[bool], np.ndarray, np.ndarray, np.ndarray]]: For each selected block a tuple with the following elements is returend:\n",
    "            - List[str]: Case IDs of all slices belonging to the block.\n",
    "            - List[bool]: Indicates whether a slice is a pseudo label or not.\n",
    "            - np.ndarray: Image slices of the block\n",
    "            - np.ndarray: Labels of the slices (true labels for the top and bottom slice, pseudo-labels for itermediate slices)\n",
    "            - np.ndarray: True labels of all slices.\n",
    "    \"\"\"\n",
    "    \n",
    "    run = api.run(f\"/active-segmentation/{project_name}/runs/{run_id}\")\n",
    "    table_file = f\"{run.name}_{run.id}.csv\"\n",
    "\n",
    "    if not os.path.exists(table_file):\n",
    "        download_all_tables(run_id, entity_name, project_name, table_name)\n",
    "\n",
    "    selected_slices = pd.read_csv(table_file)\n",
    "\n",
    "    selected_slices = selected_slices[selected_slices[\"iteration\"] == iteration]\n",
    "\n",
    "    true_labels = selected_slices[selected_slices[\"pseudo_label\"] == False]\n",
    "    pseudo_labels = selected_slices[selected_slices[\"pseudo_label\"] == True]\n",
    "\n",
    "    selected_blocks = []\n",
    "\n",
    "    for idx, bottom_slice in true_labels.iterrows():\n",
    "        if idx % 2 == 1:\n",
    "            image_path = bottom_slice[\"image_path\"]\n",
    "            label_path = image_path.replace(\"imagesTr\", \"labelsTr\")\n",
    "\n",
    "            image =  nib.load(image_path).get_fdata()\n",
    "            image = np.moveaxis(image, 2, 0)\n",
    "\n",
    "            label = nib.load(label_path).get_fdata()\n",
    "            label = np.moveaxis(label, 2, 0)\n",
    "\n",
    "            slices = []\n",
    "            labels = []\n",
    "            original_labels = []\n",
    "            case_ids = []\n",
    "            is_pseudo_label = []\n",
    "\n",
    "            case_ids.append(bottom_slice[\"case_id\"])\n",
    "            slices.append(image[bottom_slice[\"slice_index\"]])\n",
    "            labels.append(label[bottom_slice[\"slice_index\"]])\n",
    "            original_labels.append(label[bottom_slice[\"slice_index\"]])\n",
    "            is_pseudo_label.append(False)\n",
    "\n",
    "            top_slice = true_labels.iloc[idx-1]\n",
    "\n",
    "            interpolated_slices = pseudo_labels[\n",
    "                (pseudo_labels[\"image_id\"] == bottom_slice[\"image_id\"]) &\n",
    "                (pseudo_labels[\"slice_index\"] > bottom_slice[\"slice_index\"]) &\n",
    "                (pseudo_labels[\"slice_index\"] < top_slice[\"slice_index\"])\n",
    "            ]\n",
    "\n",
    "            interpolated_slices = interpolated_slices.sort_values(by=['slice_index'])\n",
    "\n",
    "            bottom_slice_idx = bottom_slice[\"slice_index\"]\n",
    "            top_slice_idx = top_slice[\"slice_index\"]\n",
    "\n",
    "            if len(interpolated_slices) > 0:\n",
    "                interpolated_labels = interpolate_slices(label[bottom_slice_idx], label[top_slice_idx], class_ids, len(interpolated_slices) + 2, interpolation_type)\n",
    "\n",
    "                if interpolated_slices is not None:\n",
    "                    for inner_idx, (_, interpolated_slice) in enumerate(interpolated_slices.iterrows()):\n",
    "                        case_ids.append(interpolated_slice[\"case_id\"])\n",
    "                        slices.append(image[interpolated_slice[\"slice_index\"]])\n",
    "                        labels.append(interpolated_labels[inner_idx])\n",
    "                        original_labels.append(label[interpolated_slice[\"slice_index\"]])\n",
    "                        is_pseudo_label.append(True)\n",
    "\n",
    "            case_ids.append(top_slice[\"case_id\"])\n",
    "            slices.append(image[top_slice[\"slice_index\"]])\n",
    "            labels.append(label[top_slice[\"slice_index\"]])\n",
    "            original_labels.append(label[top_slice[\"slice_index\"]])\n",
    "            is_pseudo_label.append(False)\n",
    "\n",
    "            selected_blocks.append((case_ids, is_pseudo_label, slices, labels, original_labels))\n",
    "\n",
    "    return selected_blocks\n",
    "\n",
    "def visualize_selected_blocks(selected_blocks: List[Tuple[List[str], List[bool], np.ndarray, np.ndarray, np.ndarray]],\n",
    "                                image_size: int = 5,\n",
    "                                max_images_per_row: int = 3) -> None:\n",
    "    \"\"\"\n",
    "    Plots blocks selected in an active learning iteration.\n",
    "\n",
    "    Args:\n",
    "        selected_blocks (List[Tuple[List[str], List[bool], np.ndarray, np.ndarray, np.ndarray]]): Selected blocks as returned by `get_selected_blocks`.\n",
    "        image_size (int, optional): Size in which the images should be displayed in inches. Defaults to 5.\n",
    "        max_images_per_row (int, optional): Maximum number of images to be displayed in one row. Defaults to 3.\n",
    "    \"\"\"\n",
    "    for block in selected_blocks:\n",
    "        case_ids, is_pseudo_label, slices, labels, true_labels = block\n",
    "\n",
    "        n_rows = math.ceil(len(slices) / max_images_per_row)\n",
    "\n",
    "        plt.figure(figsize=(image_size * max_images_per_row, image_size * n_rows))\n",
    "\n",
    "        for idx, image in enumerate(slices):\n",
    "            plt.subplot(n_rows, max_images_per_row, idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image, cmap='gray')\n",
    "\n",
    "            if labels is not None:\n",
    "                cmap = cm.Accent.copy()\n",
    "                cmap.set_under('k', alpha=0)\n",
    "\n",
    "                plt.axis('off')\n",
    "                plt.imshow(labels[idx], cmap=cmap, alpha=0.7, clim=[0.9, 10])\n",
    "                plt.title(f\"{case_ids[idx]} - {'interpolated label' if is_pseudo_label[idx] else 'true label'}\")\n",
    "\n",
    "                if is_pseudo_label[idx]:\n",
    "                    cmap = cm.plasma.copy()\n",
    "                    cmap.set_under('k', alpha=0)\n",
    "                    true_label_diff = true_labels[idx].copy()\n",
    "                    true_label_diff[true_labels[idx] == labels[idx]] = 0\n",
    "                    plt.axis('off')\n",
    "                    plt.imshow(true_label_diff, cmap=cmap, alpha=1, clim=[0.9, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_name = \"/dhc/groups/mpws2021cl1/Data/Decathlon/Task02_Heart/dataset.json\"\n",
    "entity_name = \"active-segmentation\"\n",
    "project_name = \"task-02-heart-paper\"\n",
    "table_name = \"selected_items\"\n",
    "\n",
    "with open(dataset_file_name, encoding=\"utf-8\") as dataset_file:\n",
    "    dataset_info = json.load(dataset_file)\n",
    "    labels = dataset_info[\"labels\"]\n",
    "class_ids = {int(key): labels[key] for key in labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"2fns4wu0\"\n",
    "\n",
    "selected_blocks = get_selected_blocks(run_id, entity_name, project_name, table_name, 1, class_ids, \"signed-distance\")\n",
    "\n",
    "visualize_selected_blocks(selected_blocks)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
